{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yut.engine\n",
    "from example_player import ExamplePlayer\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax YeThu Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_goal = np.zeros( yut.rule.FINISHED+1 )\n",
    "outcomes, probs = yut.rule.enumerate_all_cast_outcomes(depth=5)\n",
    "\n",
    "for _ in range(10):\n",
    "\tfor s in range(yut.rule.FINISHED):\n",
    "\t\tweighted_sum = 0.0\n",
    "\t\tfor outcome, prob in zip( outcomes, probs ):\n",
    "\t\t\tpos = s\n",
    "\t\t\tfor ys in outcome:\n",
    "\t\t\t\tpos = yut.rule.next_position( pos, ys, True )\n",
    "\t\t\tweighted_sum += ( 1 + distance_to_goal[pos] ) * prob \n",
    "\t\tdistance_to_goal[s] = weighted_sum\n",
    "\n",
    "class MinimaxYethuPlayer(yut.engine.Player):\n",
    "    def __init__(self, max_depth=2):\n",
    "        \"\"\"\n",
    "        Initialize the Minimax player with configurable search depth\n",
    "        \n",
    "        Args:\n",
    "            max_depth (int): Maximum depth to search in the game tree\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def _evaluate_board_state(self, my_positions, enemy_positions):\n",
    "        my_duplicates = [ sum(np == p for np in my_positions) for p in my_positions ]\n",
    "        enemy_duplicates = [ sum(np == p for np in enemy_positions) for p in enemy_positions ]\n",
    "        # multipliers = [ 1, 0.85, 0.7, 0.55, 0.4 ] # best aginst random player\n",
    "        multipliers = [ 1, 1, 0.7, 0.4, 0.3 ] # best aginst example player\n",
    "     \n",
    "        return - sum( distance_to_goal[p] * (multipliers[np] if p != 0 else 1) for p,np in zip(my_positions,my_duplicates) ) \\\n",
    "                + sum( distance_to_goal[p] * (multipliers[np] if p != 0 else 1) for p,np in zip(enemy_positions,enemy_duplicates) ) \\\n",
    "    \n",
    "    def _is_shortcut_possible(self, position):\n",
    "        shortcut_positions = {15, 22, 29} \n",
    "        return position in shortcut_positions\n",
    "    \n",
    "    def minimax(self, my_positions, enemy_positions, available_yutscores, depth, is_maximizing):\n",
    "        \"\"\"\n",
    "        Minimax algorithm with robust move validation\n",
    "        \n",
    "        Args:\n",
    "            my_positions (list): Current player's piece positions\n",
    "            enemy_positions (list): Opponent's piece positions\n",
    "            available_yutscores (list): Available move distances\n",
    "            depth (int): Current search depth\n",
    "            is_maximizing (bool): Whether it's maximizing player's turn\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (best_score, best_move)\n",
    "        \"\"\"\n",
    "        # Terminal conditions\n",
    "        if depth == 0:\n",
    "            return self._evaluate_board_state(my_positions, enemy_positions), None\n",
    "        \n",
    "        # Determine current player's positions based on turn\n",
    "        current_positions = my_positions if is_maximizing else enemy_positions\n",
    "        # other_positions = enemy_positions if is_maximizing else my_positions\n",
    "        \n",
    "        best_score = float('-inf') if is_maximizing else float('inf')\n",
    "        best_move = None\n",
    "        \n",
    "        # Filter out invalid move combinations beforehand\n",
    "        for mal_index, mal_pos in enumerate(current_positions):\n",
    "            if mal_pos == yut.rule.FINISHED:\n",
    "                continue\n",
    "            \n",
    "    \n",
    "            for ys in available_yutscores:\n",
    "                shortcuts = [True, False] if self._is_shortcut_possible(mal_pos) else [False]\n",
    "                \n",
    "                for shortcut in shortcuts:        \n",
    "                    # Simulate move with error handling\n",
    "                    if is_maximizing:\n",
    "                        legal_move, next_my_positions, next_enemy_positions, mal_caught = yut.rule.make_move(\n",
    "                            my_positions, enemy_positions, mal_index, ys, shortcut\n",
    "                        )\n",
    "                    else:\n",
    "                        legal_move, next_enemy_positions, next_my_positions, mal_caught = yut.rule.make_move(\n",
    "                            enemy_positions, my_positions, mal_index, ys, shortcut\n",
    "                        )\n",
    "                    \n",
    "                    if not legal_move:\n",
    "                        continue\n",
    "            \n",
    "                    # Recursive minimax call\n",
    "                    scores = []\n",
    "                    outcomes, probs = yut.rule.enumerate_all_cast_outcomes(depth=1)\n",
    "                    for outcome, prob in zip(outcomes, probs):\n",
    "                        for next_ys in outcome:\n",
    "                            score, _ = self.minimax(next_my_positions, next_enemy_positions, [next_ys], depth - 1, not is_maximizing)\n",
    "                      \n",
    "                            scores.append(score) \n",
    "                            \n",
    "                          \n",
    "                    # Update best score and move\n",
    "                    score = np.max(scores) if is_maximizing else np.min(scores)\n",
    "                    \n",
    "                    if is_maximizing:\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_move = (mal_index, ys, shortcut)\n",
    "                    else:\n",
    "                        if score < best_score:\n",
    "                            best_score = score\n",
    "                            best_move = (mal_index, ys, shortcut)\n",
    "        \n",
    "        return best_score, best_move\n",
    "\n",
    "    def action(self, state):\n",
    "        \"\"\"\n",
    "        Determine the best action for the current game state\n",
    "        \n",
    "        Args:\n",
    "            state (tuple): Current game state \n",
    "                           (turn, my_positions, enemy_positions, available_yutscores)\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Move details (mal_index, yut_score, shortcut, extra_info)\n",
    "        \"\"\"\n",
    "        _, my_positions, enemy_positions, available_yutscores = state\n",
    "        # Run minimax to find best move\n",
    "        _, best_move = self.minimax(my_positions, enemy_positions, available_yutscores, depth=self.max_depth, is_maximizing=True)\n",
    "        \n",
    "        # If no valid move found, return a default move\n",
    "        if best_move is None:\n",
    "            # Try to find any legal move\n",
    "            for mal_index, mal_pos in enumerate(my_positions):\n",
    "                if mal_pos == yut.rule.FINISHED:\n",
    "                    continue\n",
    "                for ys in available_yutscores:\n",
    "                    for shortcut in [True, False]:\n",
    "                        legal_move, _, _, _ = yut.rule.make_move(my_positions, enemy_positions, mal_index, ys, shortcut)\n",
    "                        if legal_move:\n",
    "                            return mal_index, ys, shortcut, \"\"\n",
    "            \n",
    "            # Absolute fallback\n",
    "            return 0, available_yutscores[0], True, \"\"\n",
    "        \n",
    "        return best_move[0], best_move[1], best_move[2], \"\"\n",
    "    \n",
    "    \n",
    "    def name(self):\n",
    "        return \"Robust Minimax Player\"\n",
    "    \n",
    "    def on_my_action(self, state, my_action, result):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Player 2 won!\n",
      "1: Player 2 won!\n",
      "2: Player 2 won!\n",
      "3: Player 1 won!\n",
      "4: Player 2 won!\n",
      "5: Player 2 won!\n",
      "6: Player 2 won!\n",
      "7: Player 2 won!\n",
      "8: Player 2 won!\n",
      "9: Player 2 won!\n",
      "10: Player 1 won!\n",
      "11: Player 1 won!\n",
      "12: Player 2 won!\n",
      "13: Player 2 won!\n",
      "14: Player 2 won!\n",
      "15: Player 2 won!\n",
      "16: Player 1 won!\n",
      "17: Player 2 won!\n",
      "18: Player 2 won!\n",
      "19: Player 1 won!\n",
      "20: Player 1 won!\n",
      "21: Player 2 won!\n",
      "22: Player 1 won!\n",
      "23: Player 1 won!\n",
      "24: Player 2 won!\n",
      "25: Player 1 won!\n",
      "26: Player 1 won!\n",
      "27: Player 2 won!\n",
      "28: Player 1 won!\n",
      "29: Player 1 won!\n",
      "30: Player 2 won!\n",
      "31: Player 2 won!\n",
      "32: Player 1 won!\n",
      "33: Player 2 won!\n",
      "34: Player 2 won!\n",
      "35: Player 2 won!\n",
      "36: Player 2 won!\n",
      "37: Player 2 won!\n",
      "38: Player 1 won!\n",
      "39: Player 1 won!\n",
      "40: Player 2 won!\n",
      "41: Player 1 won!\n",
      "42: Player 2 won!\n",
      "43: Player 1 won!\n",
      "44: Player 2 won!\n",
      "45: Player 1 won!\n",
      "46: Player 1 won!\n",
      "47: Player 2 won!\n",
      "48: Player 1 won!\n",
      "49: Player 2 won!\n",
      "50: Player 2 won!\n",
      "51: Player 1 won!\n",
      "52: Player 2 won!\n",
      "53: Player 1 won!\n",
      "54: Player 1 won!\n",
      "55: Player 2 won!\n",
      "56: Player 2 won!\n",
      "57: Player 1 won!\n",
      "58: Player 2 won!\n",
      "59: Player 2 won!\n",
      "60: Player 1 won!\n",
      "61: Player 1 won!\n",
      "62: Player 1 won!\n",
      "63: Player 1 won!\n",
      "64: Player 1 won!\n",
      "65: Player 1 won!\n",
      "66: Player 1 won!\n",
      "67: Player 1 won!\n",
      "68: Player 2 won!\n",
      "69: Player 2 won!\n",
      "70: Player 1 won!\n",
      "71: Player 1 won!\n",
      "72: Player 1 won!\n",
      "73: Player 1 won!\n",
      "74: Player 2 won!\n",
      "75: Player 1 won!\n",
      "76: Player 2 won!\n",
      "77: Player 1 won!\n",
      "78: Player 2 won!\n",
      "79: Player 1 won!\n",
      "80: Player 1 won!\n",
      "81: Player 1 won!\n",
      "82: Player 1 won!\n",
      "83: Player 1 won!\n",
      "84: Player 2 won!\n",
      "85: Player 1 won!\n",
      "86: Player 2 won!\n",
      "87: Player 1 won!\n",
      "88: Player 1 won!\n",
      "89: Player 1 won!\n",
      "90: Player 2 won!\n",
      "91: Player 1 won!\n",
      "92: Player 2 won!\n",
      "93: Player 2 won!\n",
      "94: Player 1 won!\n",
      "95: Player 1 won!\n",
      "96: Player 1 won!\n",
      "97: Player 1 won!\n",
      "98: Player 2 won!\n",
      "99: Player 1 won!\n",
      "Player 1 wins 53 times, with winrate of 0.53\n"
     ]
    }
   ],
   "source": [
    "# create a game engine\n",
    "engine = yut.engine.GameEngine()\n",
    "\n",
    "# create two game players\n",
    "player1 = MinimaxYethuPlayer()\n",
    "player2 = ExamplePlayer()\n",
    "\n",
    "# simulate a game between two players with a given random seed\n",
    "num_trial = 100\n",
    "win_rate = 0\n",
    "# random_numbers = [random.randint(1, 10000) for _ in range(num_trial)]\n",
    "random_numbers = [x for x in range(100)]\n",
    "for i, random_seed in enumerate(random_numbers):\n",
    "\twinner = engine.play( player1, player2, seed=random_seed )\n",
    "\tif winner == 0:\n",
    "\t\twin_rate += 1\n",
    "\t\tprint( str(i) + \": Player 1 won!\" )\n",
    "\telse:\n",
    "\t\tprint( str(i) + \": Player 2 won!\" )\n",
    "\n",
    "print(\"Player 1 wins \" + str(win_rate) + \" times, with winrate of \" + str(win_rate/num_trial) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax Akira's Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class RandomPlayer(yut.engine.Player):\n",
    "\tdef name(self):\n",
    "\t\treturn \"Random\"\n",
    "\n",
    "\tdef action(self, state):\n",
    "\t\tturn, my_positions, enemy_positions, available_yutscores = state\n",
    "\t\tyutscore_to_use = np.random.choice( available_yutscores )\n",
    "\t\tavailable_mals = []\n",
    "\t\tif yutscore_to_use == -1:\n",
    "\t\t\tavailable_mals = [ mal_index for mal_index,mal_position in enumerate(my_positions) if mal_position != yut.rule.FINISHED and mal_position != 0 ]\n",
    "\t\tif len(available_mals) == 0:\n",
    "\t\t\tavailable_mals = [ mal_index for mal_index,mal_position in enumerate(my_positions) if mal_position != yut.rule.FINISHED ]\n",
    "\t\tmal_to_move = np.random.choice( available_mals )\n",
    "\t\tshortcut = True\n",
    "\t\tdebug_msg = \"\"\n",
    "\n",
    "\t\treturn mal_to_move, yutscore_to_use, shortcut, debug_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_goal = np.zeros( yut.rule.FINISHED+1 )\n",
    "\n",
    "outcomes, probs = yut.rule.enumerate_all_cast_outcomes(depth=2)\n",
    "\n",
    "for _ in range(10):\n",
    "\tfor s in range(yut.rule.FINISHED):\n",
    "\t\tweighted_sum = 0.0\n",
    "\t\tfor outcome, prob in zip( outcomes, probs ):\n",
    "\t\t\tpos = s\n",
    "\t\t\tfor ys in outcome:\n",
    "\t\t\t\tpos = yut.rule.next_position( pos, ys, True )\n",
    "\t\t\tweighted_sum += ( 0.05 + distance_to_goal[pos] ) * prob \n",
    "\t\tdistance_to_goal[s] = weighted_sum\n",
    "\n",
    "class MinimaxAkiraPlayer(yut.engine.Player):\n",
    "    def __init__(self, max_depth=2):\n",
    "        \"\"\"\n",
    "        Initialize the Minimax player with configurable search depth\n",
    "        \n",
    "        Args:\n",
    "            max_depth (int): Maximum depth to search in the game tree\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def _evaluate_board_state(self, my_positions, enemy_positions, mal_caught):\n",
    "        my_duplicates = [sum(np == p for np in my_positions) for p in my_positions]\n",
    "        enemy_duplicates = [sum(np == p for np in enemy_positions) for p in enemy_positions]\n",
    "        multipliers = [1, 1, 0.7, 0.4, 0.3]  # For evaluating based on the distance\n",
    "\n",
    "        vulnerable_map = {0: [], 1: [], 2: [0], 3:[0, 1], 4: [1, 2], 5: [2, 3], 6:[3, 4], 7:[4], 8:[6], 9: [6,7], 10: [7,8], \n",
    "                          11: [], 12:[10], 13:[], 14:[5], 15:[10,11,5,13], 16: [13,14], 17:[14], 18:[8,9], 19:[9], 20:[18], \n",
    "                          21:[18,19], 22:[19,20,16], 23:[11,12], 24:[12,15], 25:[20,21,16,17], 26:[17,21,22], 27:[22,25], 28:[25,26], 29:[26,27], 30:[]}\n",
    "\n",
    "        capture_bonus = 0.05  # Bonus for capturing an enemy's mal\n",
    "        landing_penalty = -0.01\n",
    "\n",
    "\n",
    "        # Uncomment for default\n",
    "        # capture_bonus = 0  # Bonus for capturing an enemy's mal\n",
    "        # shortcut_bonus = 0  # Bonus for landing on a shortcut position\n",
    "        # landing_penalty = 0\n",
    "    \n",
    "        \n",
    "\n",
    "        # Initialize evaluation score\n",
    "        evaluation = 0\n",
    "\n",
    "        # Evaluate the player's positions\n",
    "        for p, np in zip(my_positions, my_duplicates):\n",
    "            multiplier = multipliers[np] if p != 0 else 1\n",
    "            evaluation -= distance_to_goal[p] * multiplier\n",
    "            \n",
    "            # Add bonus for capturing an enemy's mal\n",
    "            if p in enemy_positions:\n",
    "                evaluation += capture_bonus\n",
    "            # Penalize if the player's mal is 2 or 3 tiles ahead of any enemy piece\n",
    "            for enemy_pos in enemy_positions:\n",
    "                if enemy_pos in vulnerable_map[p]:\n",
    "                    evaluation += landing_penalty*len(vulnerable_map[p])\n",
    "        \n",
    "        # Evaluate the enemy's positions\n",
    "        for p, np in zip(enemy_positions, enemy_duplicates):\n",
    "            multiplier = multipliers[np] if p != 0 else 1\n",
    "            evaluation += distance_to_goal[p] * multiplier\n",
    "\n",
    "            # Add penalty for the enemy capturing a mal\n",
    "            if p in my_positions:\n",
    "                evaluation += capture_bonus\n",
    "            # Penalize if the enemy's mal is 2 or 3 tiles ahead of our piece\n",
    "            for my_pos in my_positions:\n",
    "                if my_pos in vulnerable_map[p]:\n",
    "                    evaluation -= landing_penalty*len(vulnerable_map[p])\n",
    "\n",
    "        return evaluation\n",
    "\n",
    "    \n",
    "    def _is_shortcut_possible(self, position):\n",
    "        shortcut_positions = {15, 22, 29} \n",
    "        return position in shortcut_positions\n",
    "    \n",
    "\n",
    "    def minimax(self, my_positions, enemy_positions, available_yutscores, depth, alpha, beta, is_maximizing, mal_caught):\n",
    "\n",
    "        if depth == 0:\n",
    "            return self._evaluate_board_state(my_positions, enemy_positions, mal_caught), None\n",
    "\n",
    "        current_positions = my_positions if is_maximizing else enemy_positions\n",
    "\n",
    "        best_score = float('-inf') if is_maximizing else float('inf')\n",
    "        best_move = None\n",
    "\n",
    "        for mal_index, mal_pos in enumerate(current_positions):\n",
    "            # Skip finished pieces\n",
    "            if mal_pos == yut.rule.FINISHED:\n",
    "                continue\n",
    "\n",
    "            for ys in available_yutscores:\n",
    "                # shortcut possibility\n",
    "                shortcuts = [True, False] if self._is_shortcut_possible(mal_pos) else [False]\n",
    "\n",
    "                for shortcut in shortcuts:\n",
    "                    # Simulate\n",
    "                    if is_maximizing:\n",
    "                        legal_move, next_my_positions, next_enemy_positions, mal_caught = yut.rule.make_move(\n",
    "                            my_positions, enemy_positions, mal_index, ys, shortcut\n",
    "                        )\n",
    "                    else:\n",
    "                        legal_move, next_enemy_positions, next_my_positions, mal_caught = yut.rule.make_move(\n",
    "                            enemy_positions, my_positions, mal_index, ys, shortcut\n",
    "                        )\n",
    "\n",
    "                    if not legal_move:\n",
    "                        continue\n",
    "\n",
    "                    # Recursive call to minimax with Alpha-Beta Pruning\n",
    "                    scores = []\n",
    "                    outcomes, probs = yut.rule.enumerate_all_cast_outcomes(depth=1)\n",
    "\n",
    "                    for outcome, prob in zip(outcomes, probs):\n",
    "                        for next_ys in outcome:\n",
    "                            score, _ = self.minimax(\n",
    "                                next_my_positions, \n",
    "                                next_enemy_positions, \n",
    "                                [next_ys], \n",
    "                                depth - 1, \n",
    "                                alpha, \n",
    "                                beta, \n",
    "                                not is_maximizing,\n",
    "                                mal_caught\n",
    "                            )\n",
    "\n",
    "                            \n",
    "                            scores.append(score)\n",
    "                    # Calculate the best score based on the player's role\n",
    "                    score = np.max(scores) if is_maximizing else np.min(scores)\n",
    "\n",
    "                    # Update best score and best move\n",
    "                    if is_maximizing:\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_move = (mal_index, ys, shortcut)\n",
    "\n",
    "                        # Alpha-Beta Pruning\n",
    "                        alpha = max(alpha, best_score)\n",
    "                        if alpha >= beta:\n",
    "                            return best_score, best_move  # Prune remaining branches\n",
    "                    else:\n",
    "                        if score < best_score:\n",
    "                            best_score = score\n",
    "                            best_move = (mal_index, ys, shortcut)\n",
    "\n",
    "                        # Alpha-Beta Pruning\n",
    "                        beta = min(beta, best_score)\n",
    "                        if beta <= alpha:\n",
    "                            return best_score, best_move  # Prune remaining branches\n",
    "\n",
    "        return best_score, best_move\n",
    "\n",
    "    def action(self, state):\n",
    "        \n",
    "        _, my_positions, enemy_positions, available_yutscores = state\n",
    "        # Run minimax with Alpha-Beta Pruning to find the best move\n",
    "        _, best_move = self.minimax(\n",
    "            my_positions, enemy_positions, available_yutscores, \n",
    "            depth=self.max_depth, \n",
    "            alpha=float('-inf'), \n",
    "            beta=float('inf'), \n",
    "            is_maximizing=True,\n",
    "            mal_caught=0\n",
    "        )\n",
    "\n",
    "        # If no valid move found, return a default move\n",
    "        if best_move is None:\n",
    "            # Try to find any legal move\n",
    "            for mal_index, mal_pos in enumerate(my_positions):\n",
    "                if mal_pos == yut.rule.FINISHED:\n",
    "                    continue\n",
    "                for ys in available_yutscores:\n",
    "                    for shortcut in [True, False]:\n",
    "                        legal_move, _, _, _ = yut.rule.make_move(my_positions, enemy_positions, mal_index, ys, shortcut)\n",
    "                        if legal_move:\n",
    "                            return mal_index, ys, shortcut, \"\"\n",
    "\n",
    "            # Absolute fallback\n",
    "            return 0, available_yutscores[0], True, \"\"\n",
    "\n",
    "        return best_move[0], best_move[1], best_move[2], \"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    def name(self):\n",
    "        return \"Minimax Player\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Player 2 won!\n",
      "1: Player 1 won!\n",
      "2: Player 2 won!\n",
      "3: Player 2 won!\n",
      "4: Player 2 won!\n",
      "5: Player 1 won!\n",
      "6: Player 1 won!\n",
      "7: Player 2 won!\n",
      "8: Player 1 won!\n",
      "9: Player 2 won!\n",
      "10: Player 2 won!\n",
      "11: Player 1 won!\n",
      "12: Player 2 won!\n",
      "13: Player 1 won!\n",
      "14: Player 2 won!\n",
      "15: Player 2 won!\n",
      "16: Player 2 won!\n",
      "17: Player 2 won!\n",
      "18: Player 2 won!\n",
      "19: Player 1 won!\n",
      "20: Player 2 won!\n",
      "21: Player 2 won!\n",
      "22: Player 1 won!\n",
      "23: Player 1 won!\n",
      "24: Player 2 won!\n",
      "25: Player 2 won!\n",
      "26: Player 2 won!\n",
      "27: Player 2 won!\n",
      "28: Player 1 won!\n",
      "29: Player 2 won!\n",
      "30: Player 2 won!\n",
      "31: Player 2 won!\n",
      "32: Player 2 won!\n",
      "33: Player 2 won!\n",
      "34: Player 2 won!\n",
      "35: Player 1 won!\n",
      "36: Player 1 won!\n",
      "37: Player 2 won!\n",
      "38: Player 1 won!\n",
      "39: Player 1 won!\n",
      "40: Player 2 won!\n",
      "41: Player 2 won!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m random_numbers \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, random_seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(random_numbers):\n\u001b[0;32m---> 14\u001b[0m \twinner \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m winner \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m \t\twin_rate \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/KAIST/COE202/CoE202_final/final/yut/engine.py:252\u001b[0m, in \u001b[0;36mGameEngine.play\u001b[0;34m(self, player1, player2, game_states, game_actions, seed, game_event_listener)\u001b[0m\n\u001b[1;32m    250\u001b[0m turn \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m \twinner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_single_turn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mturn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_event_listener\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame_actions\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m winner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m \t\t\u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/KAIST/COE202/CoE202_final/final/yut/engine.py:188\u001b[0m, in \u001b[0;36mGameEngine.play_single_turn\u001b[0;34m(self, turn, event_listener, game_states, game_actions)\u001b[0m\n\u001b[1;32m    185\u001b[0m legal_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m \taction \u001b[38;5;241m=\u001b[39m mal_to_move, yutscore_to_use, shortcut, debug_msg \u001b[38;5;241m=\u001b[39m \u001b[43mme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \t\u001b[38;5;66;03m# print( \"***action:\", action )\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "Cell \u001b[0;32mIn[46], line 163\u001b[0m, in \u001b[0;36mMinimaxAkiraPlayer.action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    161\u001b[0m _, my_positions, enemy_positions, available_yutscores \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Run minimax with Alpha-Beta Pruning to find the best move\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m _, best_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmy_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menemy_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_yutscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-inf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_maximizing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmal_caught\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# If no valid move found, return a default move\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_move \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# Try to find any legal move\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[46], line 121\u001b[0m, in \u001b[0;36mMinimaxAkiraPlayer.minimax\u001b[0;34m(self, my_positions, enemy_positions, available_yutscores, depth, alpha, beta, is_maximizing, mal_caught)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m outcome, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outcomes, probs):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m next_ys \u001b[38;5;129;01min\u001b[39;00m outcome:\n\u001b[0;32m--> 121\u001b[0m         score, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnext_my_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnext_enemy_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_ys\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_maximizing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmal_caught\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Calculate the best score based on the player's role\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[46], line 121\u001b[0m, in \u001b[0;36mMinimaxAkiraPlayer.minimax\u001b[0;34m(self, my_positions, enemy_positions, available_yutscores, depth, alpha, beta, is_maximizing, mal_caught)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m outcome, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outcomes, probs):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m next_ys \u001b[38;5;129;01min\u001b[39;00m outcome:\n\u001b[0;32m--> 121\u001b[0m         score, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnext_my_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnext_enemy_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_ys\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_maximizing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmal_caught\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Calculate the best score based on the player's role\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[46], line 85\u001b[0m, in \u001b[0;36mMinimaxAkiraPlayer.minimax\u001b[0;34m(self, my_positions, enemy_positions, available_yutscores, depth, alpha, beta, is_maximizing, mal_caught)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimax\u001b[39m(\u001b[38;5;28mself\u001b[39m, my_positions, enemy_positions, available_yutscores, depth, alpha, beta, is_maximizing, mal_caught):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_board_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menemy_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmal_caught\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     current_positions \u001b[38;5;241m=\u001b[39m my_positions \u001b[38;5;28;01mif\u001b[39;00m is_maximizing \u001b[38;5;28;01melse\u001b[39;00m enemy_positions\n\u001b[1;32m     89\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m is_maximizing \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m, in \u001b[0;36mMinimaxAkiraPlayer._evaluate_board_state\u001b[0;34m(self, my_positions, enemy_positions, mal_caught)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_board_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, my_positions, enemy_positions, mal_caught):\n\u001b[1;32m     26\u001b[0m     my_duplicates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(np \u001b[38;5;241m==\u001b[39m p \u001b[38;5;28;01mfor\u001b[39;00m np \u001b[38;5;129;01min\u001b[39;00m my_positions) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m my_positions]\n\u001b[0;32m---> 27\u001b[0m     enemy_duplicates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menemy_positions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m enemy_positions]\n\u001b[1;32m     28\u001b[0m     multipliers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]  \u001b[38;5;66;03m# For evaluating based on the distance\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     vulnerable_map \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: [], \u001b[38;5;241m1\u001b[39m: [], \u001b[38;5;241m2\u001b[39m: [\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m3\u001b[39m:[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m4\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m5\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], \u001b[38;5;241m6\u001b[39m:[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m], \u001b[38;5;241m7\u001b[39m:[\u001b[38;5;241m4\u001b[39m], \u001b[38;5;241m8\u001b[39m:[\u001b[38;5;241m6\u001b[39m], \u001b[38;5;241m9\u001b[39m: [\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m], \u001b[38;5;241m10\u001b[39m: [\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m], \n\u001b[1;32m     31\u001b[0m                       \u001b[38;5;241m11\u001b[39m: [], \u001b[38;5;241m12\u001b[39m:[\u001b[38;5;241m10\u001b[39m], \u001b[38;5;241m13\u001b[39m:[], \u001b[38;5;241m14\u001b[39m:[\u001b[38;5;241m5\u001b[39m], \u001b[38;5;241m15\u001b[39m:[\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m13\u001b[39m], \u001b[38;5;241m16\u001b[39m: [\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m14\u001b[39m], \u001b[38;5;241m17\u001b[39m:[\u001b[38;5;241m14\u001b[39m], \u001b[38;5;241m18\u001b[39m:[\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m], \u001b[38;5;241m19\u001b[39m:[\u001b[38;5;241m9\u001b[39m], \u001b[38;5;241m20\u001b[39m:[\u001b[38;5;241m18\u001b[39m], \n\u001b[1;32m     32\u001b[0m                       \u001b[38;5;241m21\u001b[39m:[\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m19\u001b[39m], \u001b[38;5;241m22\u001b[39m:[\u001b[38;5;241m19\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m16\u001b[39m], \u001b[38;5;241m23\u001b[39m:[\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m], \u001b[38;5;241m24\u001b[39m:[\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m15\u001b[39m], \u001b[38;5;241m25\u001b[39m:[\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m21\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m17\u001b[39m], \u001b[38;5;241m26\u001b[39m:[\u001b[38;5;241m17\u001b[39m,\u001b[38;5;241m21\u001b[39m,\u001b[38;5;241m22\u001b[39m], \u001b[38;5;241m27\u001b[39m:[\u001b[38;5;241m22\u001b[39m,\u001b[38;5;241m25\u001b[39m], \u001b[38;5;241m28\u001b[39m:[\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m26\u001b[39m], \u001b[38;5;241m29\u001b[39m:[\u001b[38;5;241m26\u001b[39m,\u001b[38;5;241m27\u001b[39m], \u001b[38;5;241m30\u001b[39m:[]}\n",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_board_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, my_positions, enemy_positions, mal_caught):\n\u001b[1;32m     26\u001b[0m     my_duplicates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(np \u001b[38;5;241m==\u001b[39m p \u001b[38;5;28;01mfor\u001b[39;00m np \u001b[38;5;129;01min\u001b[39;00m my_positions) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m my_positions]\n\u001b[0;32m---> 27\u001b[0m     enemy_duplicates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(np \u001b[38;5;241m==\u001b[39m p \u001b[38;5;28;01mfor\u001b[39;00m np \u001b[38;5;129;01min\u001b[39;00m enemy_positions) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m enemy_positions]\n\u001b[1;32m     28\u001b[0m     multipliers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.3\u001b[39m]  \u001b[38;5;66;03m# For evaluating based on the distance\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     vulnerable_map \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: [], \u001b[38;5;241m1\u001b[39m: [], \u001b[38;5;241m2\u001b[39m: [\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m3\u001b[39m:[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m4\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m5\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], \u001b[38;5;241m6\u001b[39m:[\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m], \u001b[38;5;241m7\u001b[39m:[\u001b[38;5;241m4\u001b[39m], \u001b[38;5;241m8\u001b[39m:[\u001b[38;5;241m6\u001b[39m], \u001b[38;5;241m9\u001b[39m: [\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m], \u001b[38;5;241m10\u001b[39m: [\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m], \n\u001b[1;32m     31\u001b[0m                       \u001b[38;5;241m11\u001b[39m: [], \u001b[38;5;241m12\u001b[39m:[\u001b[38;5;241m10\u001b[39m], \u001b[38;5;241m13\u001b[39m:[], \u001b[38;5;241m14\u001b[39m:[\u001b[38;5;241m5\u001b[39m], \u001b[38;5;241m15\u001b[39m:[\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m13\u001b[39m], \u001b[38;5;241m16\u001b[39m: [\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m14\u001b[39m], \u001b[38;5;241m17\u001b[39m:[\u001b[38;5;241m14\u001b[39m], \u001b[38;5;241m18\u001b[39m:[\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m], \u001b[38;5;241m19\u001b[39m:[\u001b[38;5;241m9\u001b[39m], \u001b[38;5;241m20\u001b[39m:[\u001b[38;5;241m18\u001b[39m], \n\u001b[1;32m     32\u001b[0m                       \u001b[38;5;241m21\u001b[39m:[\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m19\u001b[39m], \u001b[38;5;241m22\u001b[39m:[\u001b[38;5;241m19\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m16\u001b[39m], \u001b[38;5;241m23\u001b[39m:[\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m], \u001b[38;5;241m24\u001b[39m:[\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m15\u001b[39m], \u001b[38;5;241m25\u001b[39m:[\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m21\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m17\u001b[39m], \u001b[38;5;241m26\u001b[39m:[\u001b[38;5;241m17\u001b[39m,\u001b[38;5;241m21\u001b[39m,\u001b[38;5;241m22\u001b[39m], \u001b[38;5;241m27\u001b[39m:[\u001b[38;5;241m22\u001b[39m,\u001b[38;5;241m25\u001b[39m], \u001b[38;5;241m28\u001b[39m:[\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m26\u001b[39m], \u001b[38;5;241m29\u001b[39m:[\u001b[38;5;241m26\u001b[39m,\u001b[38;5;241m27\u001b[39m], \u001b[38;5;241m30\u001b[39m:[]}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create a game engine\n",
    "engine = yut.engine.GameEngine()\n",
    "\n",
    "# create two game players\n",
    "player2 = MinimaxAkiraPlayer()\n",
    "player1 = ExamplePlayer()\n",
    "\n",
    "# simulate a game between two players with a given random seed\n",
    "num_trial = 100\n",
    "win_rate = 0\n",
    "# random_numbers = [random.randint(1, 10000) for _ in range(num_trial)]\n",
    "random_numbers = [x for x in range(100)]\n",
    "for i, random_seed in enumerate(random_numbers):\n",
    "\twinner = engine.play( player1, player2, seed=random_seed )\n",
    "\tif winner == 0:\n",
    "\t\twin_rate += 1\n",
    "\t\tprint( str(i) + \": Player 1 won!\" )\n",
    "\telse:\n",
    "\t\t\n",
    "\t\tprint( str(i) + \": Player 2 won!\" )\n",
    "\n",
    "print(\"Player 1 wins \" + str(win_rate) + \" times, with win rate of \" + str(win_rate/num_trial) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax Akira Player (version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_goal = np.zeros(yut.rule.FINISHED + 1)\n",
    "\n",
    "proximity_weight = 0.5  # Increased weight for positions closer to the goal\n",
    "\n",
    "outcomes, probs = yut.rule.enumerate_all_cast_outcomes(depth=2)\n",
    "\n",
    "for _ in range(10):\n",
    "    for s in range(yut.rule.FINISHED):\n",
    "        weighted_sum = 0.0\n",
    "        for outcome, prob in zip(outcomes, probs):\n",
    "            pos = s\n",
    "            for ys in outcome:\n",
    "                pos = yut.rule.next_position(pos, ys, True)\n",
    "\n",
    "            # Base distance value\n",
    "            base_value = 0.05 + distance_to_goal[pos]\n",
    "\n",
    "            # Apply bonuses and penalties\n",
    "            weighted_sum += base_value * prob\n",
    "        distance_to_goal[s] = weighted_sum\n",
    "\n",
    "\n",
    "class MinimaxAkiraPlayer2(yut.engine.Player):\n",
    "    def __init__(self, max_depth=2): # Change depth does not really affect performance since it is mostly random dice outcomes\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def _evaluate_board_state(self, my_positions, enemy_positions, mal_caught):\n",
    "        my_duplicates = [sum(np == p for np in my_positions) for p in my_positions]\n",
    "        enemy_duplicates = [sum(np == p for np in enemy_positions) for p in enemy_positions]\n",
    "        multipliers = [1, 1, 0.7, 0.4, 0.3]  # For evaluating based on the distance\n",
    "\n",
    "        #vulnerable_map (based on statistics, gae and gol appear almost 70% of the time, making 2 or 3 tiles ahead of opponent's mal a risky poition)\n",
    "        vulnerable_map = {0: [], 1: [], 2: [0], 3:[0, 1], 4: [1, 2], 5: [2, 3], 6:[3, 4], 7:[4], 8:[6], 9: [6,7], 10: [7,8], \n",
    "                          11: [], 12:[10], 13:[], 14:[5], 15:[10,11,5,13], 16: [13,14], 17:[14], 18:[8,9], 19:[9], 20:[18], \n",
    "                          21:[18,19], 22:[19,20,16], 23:[11,12], 24:[12,15], 25:[20,21,16,17], 26:[17,21,22], 27:[22,25], 28:[25,26], 29:[26,27], 30:[]}\n",
    "\n",
    "        capture_bonus = 0.07  # Bonus for capturing an enemy's mal (Second priority after finishing the furthest mal first)\n",
    "        landing_penalty = -0.01\n",
    "\n",
    "        evaluation = 0\n",
    "\n",
    "        for p, np in zip(my_positions, my_duplicates):\n",
    "            multiplier = multipliers[np] if p != 0 else 1\n",
    "            evaluation -= distance_to_goal[p] * multiplier\n",
    "            \n",
    "            # Bonus for capturing mal\n",
    "            if p in enemy_positions:\n",
    "                evaluation += capture_bonus\n",
    "            # Penalty for high risk squre\n",
    "            for enemy_pos in enemy_positions:\n",
    "                if enemy_pos in vulnerable_map[p]:\n",
    "                    evaluation += landing_penalty*len(vulnerable_map[p]) # add penalty proportional to the riskiness\n",
    "        \n",
    "        # Evaluate the enemy's positions\n",
    "        for p, np in zip(enemy_positions, enemy_duplicates):\n",
    "            multiplier = multipliers[np] if p != 0 else 1\n",
    "            evaluation += distance_to_goal[p] * multiplier\n",
    "\n",
    "            # Penalty for capturing mal\n",
    "            if p in my_positions:\n",
    "                evaluation -= capture_bonus\n",
    "            # Bonus for high risk square\n",
    "            for my_pos in my_positions:\n",
    "                if my_pos in vulnerable_map[p]:\n",
    "                    evaluation -= landing_penalty*len(vulnerable_map[p])\n",
    "\n",
    "        return evaluation\n",
    "\n",
    "    \n",
    "    def _is_shortcut_possible(self, position):\n",
    "        shortcut_positions = {15, 22, 29} \n",
    "        return position in shortcut_positions\n",
    "    \n",
    "\n",
    "    def minimax(self, my_positions, enemy_positions, available_yutscores, depth, alpha, beta, is_maximizing, mal_caught):\n",
    "\n",
    "        # Base case\n",
    "        if depth == 0:\n",
    "            return self._evaluate_board_state(my_positions, enemy_positions, mal_caught), None\n",
    "\n",
    "        current_positions = my_positions if is_maximizing else enemy_positions\n",
    "        best_score = float('-inf') if is_maximizing else float('inf')\n",
    "        best_move = None\n",
    "\n",
    "        for mal_index, mal_pos in enumerate(current_positions):\n",
    "\n",
    "            if mal_pos == yut.rule.FINISHED:\n",
    "                continue\n",
    "\n",
    "            for ys in available_yutscores:\n",
    "                shortcuts = [True, False] if self._is_shortcut_possible(mal_pos) else [False]\n",
    "\n",
    "                for shortcut in shortcuts:\n",
    "                    # Simulate the move\n",
    "                    if is_maximizing:\n",
    "                        legal_move, next_my_positions, next_enemy_positions, mal_caught = yut.rule.make_move(\n",
    "                            my_positions, enemy_positions, mal_index, ys, shortcut\n",
    "                        )\n",
    "                    else:\n",
    "                        legal_move, next_enemy_positions, next_my_positions, mal_caught = yut.rule.make_move(\n",
    "                            enemy_positions, my_positions, mal_index, ys, shortcut\n",
    "                        )\n",
    "\n",
    "                    if not legal_move:\n",
    "                        continue\n",
    "\n",
    "                    # Recursive call to minimax with Alpha-Beta Pruning\n",
    "                    scores = []\n",
    "                    outcomes, probs = yut.rule.enumerate_all_cast_outcomes(depth=1) # can be changed, depth 3 would be the best but it takes too long. Depth 1 and 2 show no significnt difference\n",
    "\n",
    "                    for outcome, prob in zip(outcomes, probs):\n",
    "                        for next_ys in outcome:\n",
    "                            score, _ = self.minimax(\n",
    "                                next_my_positions, \n",
    "                                next_enemy_positions, \n",
    "                                [next_ys], \n",
    "                                depth - 1, \n",
    "                                alpha, \n",
    "                                beta, \n",
    "                                not is_maximizing,\n",
    "                                mal_caught\n",
    "                            )\n",
    "\n",
    "                            \n",
    "                            scores.append(score)\n",
    "                    score = np.max(scores) if is_maximizing else np.min(scores)\n",
    "\n",
    "                    # Update best score and best move\n",
    "                    if is_maximizing:\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_move = (mal_index, ys, shortcut)\n",
    "\n",
    "                        # Alpha-Beta Pruning\n",
    "                        alpha = max(alpha, best_score)\n",
    "                        if alpha >= beta:\n",
    "                            return best_score, best_move  # Prune branches\n",
    "                    else:\n",
    "                        if score < best_score:\n",
    "                            best_score = score\n",
    "                            best_move = (mal_index, ys, shortcut)\n",
    "\n",
    "                        # Alpha-Beta Pruning\n",
    "                        beta = min(beta, best_score)\n",
    "                        if beta <= alpha:\n",
    "                            return best_score, best_move  # Prune branches\n",
    "\n",
    "        return best_score, best_move\n",
    "\n",
    "    def action(self, state):\n",
    "        \"\"\"\n",
    "        Determine the best action for the current game state.\n",
    "        \n",
    "        Args:\n",
    "            state (tuple): Current game state \n",
    "                        (turn, my_positions, enemy_positions, available_yutscores)\n",
    "        \n",
    "        Returns:\n",
    "            tuple: Move details (mal_index, yut_score, shortcut, extra_info)\n",
    "        \"\"\"\n",
    "        _, my_positions, enemy_positions, available_yutscores = state\n",
    "        # Run minimax with Alpha-Beta Pruning to find the best move\n",
    "        _, best_move = self.minimax(\n",
    "            my_positions, enemy_positions, available_yutscores, \n",
    "            depth=self.max_depth, \n",
    "            alpha=float('-inf'), \n",
    "            beta=float('inf'), \n",
    "            is_maximizing=True,\n",
    "            mal_caught=0\n",
    "        )\n",
    "\n",
    "        # If no valid move found, return a default move\n",
    "        if best_move is None:\n",
    "            # Try to find any legal move\n",
    "            for mal_index, mal_pos in enumerate(my_positions):\n",
    "                if mal_pos == yut.rule.FINISHED:\n",
    "                    continue\n",
    "                for ys in available_yutscores:\n",
    "                    for shortcut in [True, False]:\n",
    "                        legal_move, _, _, _ = yut.rule.make_move(my_positions, enemy_positions, mal_index, ys, shortcut)\n",
    "                        if legal_move:\n",
    "                            return mal_index, ys, shortcut, \"\"\n",
    "\n",
    "            # Absolute fallback\n",
    "            return 0, available_yutscores[0], True, \"\"\n",
    "\n",
    "        return best_move[0], best_move[1], best_move[2], \"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    def name(self):\n",
    "        return \"Minimax Player\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Player 2 won!\n",
      "1: Player 2 won!\n",
      "2: Player 2 won!\n",
      "3: Player 2 won!\n",
      "4: Player 2 won!\n",
      "5: Player 2 won!\n",
      "6: Player 2 won!\n",
      "7: Player 2 won!\n",
      "8: Player 2 won!\n",
      "9: Player 1 won!\n",
      "10: Player 1 won!\n",
      "11: Player 1 won!\n",
      "12: Player 2 won!\n",
      "13: Player 2 won!\n",
      "14: Player 2 won!\n",
      "15: Player 2 won!\n",
      "16: Player 1 won!\n",
      "17: Player 2 won!\n",
      "18: Player 1 won!\n",
      "19: Player 1 won!\n",
      "20: Player 1 won!\n",
      "21: Player 2 won!\n",
      "22: Player 1 won!\n",
      "23: Player 2 won!\n",
      "24: Player 2 won!\n",
      "25: Player 1 won!\n",
      "26: Player 1 won!\n",
      "27: Player 2 won!\n",
      "28: Player 1 won!\n",
      "29: Player 1 won!\n",
      "30: Player 2 won!\n",
      "31: Player 2 won!\n",
      "32: Player 1 won!\n",
      "33: Player 2 won!\n",
      "34: Player 2 won!\n",
      "35: Player 2 won!\n",
      "36: Player 2 won!\n",
      "37: Player 2 won!\n",
      "38: Player 1 won!\n",
      "39: Player 1 won!\n",
      "40: Player 2 won!\n",
      "41: Player 1 won!\n",
      "42: Player 2 won!\n",
      "43: Player 1 won!\n",
      "44: Player 2 won!\n",
      "45: Player 1 won!\n",
      "46: Player 1 won!\n",
      "47: Player 2 won!\n",
      "48: Player 1 won!\n",
      "49: Player 2 won!\n",
      "50: Player 2 won!\n",
      "51: Player 1 won!\n",
      "52: Player 1 won!\n",
      "53: Player 1 won!\n",
      "54: Player 1 won!\n",
      "55: Player 2 won!\n",
      "56: Player 1 won!\n",
      "57: Player 1 won!\n",
      "58: Player 2 won!\n",
      "59: Player 2 won!\n",
      "60: Player 1 won!\n",
      "61: Player 1 won!\n",
      "62: Player 1 won!\n",
      "63: Player 1 won!\n",
      "64: Player 1 won!\n",
      "65: Player 1 won!\n",
      "66: Player 1 won!\n",
      "67: Player 1 won!\n",
      "68: Player 1 won!\n",
      "69: Player 2 won!\n",
      "70: Player 1 won!\n",
      "71: Player 1 won!\n",
      "72: Player 1 won!\n",
      "73: Player 1 won!\n",
      "74: Player 2 won!\n",
      "75: Player 1 won!\n",
      "76: Player 2 won!\n",
      "77: Player 1 won!\n",
      "78: Player 1 won!\n",
      "79: Player 1 won!\n",
      "80: Player 1 won!\n",
      "81: Player 1 won!\n",
      "82: Player 1 won!\n",
      "83: Player 1 won!\n",
      "84: Player 2 won!\n",
      "85: Player 1 won!\n",
      "86: Player 2 won!\n",
      "87: Player 1 won!\n",
      "88: Player 1 won!\n",
      "89: Player 1 won!\n",
      "90: Player 2 won!\n",
      "91: Player 1 won!\n",
      "92: Player 2 won!\n",
      "93: Player 2 won!\n",
      "94: Player 1 won!\n",
      "95: Player 1 won!\n",
      "96: Player 1 won!\n",
      "97: Player 1 won!\n",
      "98: Player 2 won!\n",
      "99: Player 1 won!\n",
      "Player 1 wins 57 times, with win rate of 0.57\n"
     ]
    }
   ],
   "source": [
    "# create a game engine\n",
    "engine = yut.engine.GameEngine()\n",
    "\n",
    "# create two game players\n",
    "player1 = MinimaxAkiraPlayer()\n",
    "player2 = ExamplePlayer()\n",
    "\n",
    "# simulate a game between two players with a given random seed\n",
    "num_trial = 100\n",
    "win_rate = 0\n",
    "# random_numbers = [random.randint(1, 10000) for _ in range(num_trial)]\n",
    "random_numbers = [x for x in range(100)]\n",
    "for i, random_seed in enumerate(random_numbers):\n",
    "\twinner = engine.play( player1, player2, seed=random_seed )\n",
    "\tif winner == 0:\n",
    "\t\twin_rate += 1\n",
    "\t\tprint( str(i) + \": Player 1 won!\" )\n",
    "\telse:\n",
    "\t\t\n",
    "\t\tprint( str(i) + \": Player 2 won!\" )\n",
    "\n",
    "print(\"Player 1 wins \" + str(win_rate) + \" times, with win rate of \" + str(win_rate/num_trial) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_goal = np.zeros(yut.rule.FINISHED + 1)\n",
    "\n",
    "proximity_weight = 0.5  # Increased weight for positions closer to the goal\n",
    "\n",
    "outcomes, probs = yut.rule.enumerate_all_cast_outcomes(depth=2)\n",
    "\n",
    "for _ in range(10):\n",
    "    for s in range(yut.rule.FINISHED):\n",
    "        weighted_sum = 0.0\n",
    "        for outcome, prob in zip(outcomes, probs):\n",
    "            pos = s\n",
    "            for ys in outcome:\n",
    "                pos = yut.rule.next_position(pos, ys, True)\n",
    "\n",
    "            # Base distance value\n",
    "            base_value = 0.05 + distance_to_goal[pos]\n",
    "\n",
    "            # Apply bonuses and penalties\n",
    "            weighted_sum += base_value * prob\n",
    "        distance_to_goal[s] = weighted_sum\n",
    "\n",
    "\n",
    "class HeuristicPlayer(yut.engine.Player):\n",
    "    def name(self):\n",
    "        return \"HeuristicImproved\"\n",
    "    \n",
    "    def evaluate_score(self, my_positions, enemy_positions, throw_again):\n",
    "        my_duplicates = [sum(np == p for np in my_positions) for p in my_positions]\n",
    "        enemy_duplicates = [sum(np == p for np in enemy_positions) for p in enemy_positions]\n",
    "        multipliers = [1, 1, 0.7, 0.4, 0.3]\n",
    "\n",
    "        vulnerable_map = {0: [], 1: [], 2: [0], 3:[0, 1], 4: [1, 2], 5: [2, 3], 6:[3, 4], 7:[4], 8:[6], 9: [6,7], 10: [7,8], \n",
    "                          11: [], 12:[10], 13:[], 14:[5], 15:[10,11,5,13], 16: [13,14], 17:[14], 18:[8,9], 19:[9], 20:[18], \n",
    "                          21:[18,19], 22:[19,20,16], 23:[11,12], 24:[12,15], 25:[20,21,16,17], 26:[17,21,22], 27:[22,25], 28:[25,26], 29:[26,27], 30:[]}\n",
    "        # Indicates which tile is risky towards other tiles\n",
    "\n",
    "        capture_bonus = 0.07  # Bonus for capturing an enemy's mal\n",
    "        shortcut_bonus = 0  # Bonus for landing on a shortcut position\n",
    "        landing_penalty = -0.01\n",
    "\n",
    "    \n",
    "        evaluation = 0\n",
    "\n",
    "        # Evaluate the player's positions\n",
    "        for p, np in zip(my_positions, my_duplicates):\n",
    "            multiplier = multipliers[np] if p != 0 else 1\n",
    "            evaluation -= distance_to_goal[p] * multiplier\n",
    "            \n",
    "            # Add bonus for capturing an enemy's mal\n",
    "            if throw_again>0:\n",
    "                evaluation += capture_bonus\n",
    "            # Penalize risky tiles\n",
    "            for enemy_pos in enemy_positions:\n",
    "                if enemy_pos in vulnerable_map[p]:\n",
    "                    evaluation += landing_penalty*len(vulnerable_map[p])\n",
    "        \n",
    "        # Evaluate the enemy's positions\n",
    "        for p, np in zip(enemy_positions, enemy_duplicates):\n",
    "            multiplier = multipliers[np] if p != 0 else 1\n",
    "            evaluation += distance_to_goal[p] * multiplier\n",
    "\n",
    "            # Add penalty for the enemy capturing our mal\n",
    "            if throw_again>0:\n",
    "                evaluation -= capture_bonus\n",
    "            # Penalize risky tiles\n",
    "            for my_pos in my_positions:\n",
    "                if my_pos in vulnerable_map[p]:\n",
    "                    evaluation -= landing_penalty*len(vulnerable_map[p])\n",
    "\n",
    "        return evaluation\n",
    "    \n",
    "    def _is_shortcut_possible(self, position):\n",
    "        shortcut_positions = {15, 22, 29} \n",
    "        return position in shortcut_positions\n",
    "\n",
    "    def action(self, state):\n",
    "        turn, my_positions, enemy_positions, available_yutscores = state\n",
    "\n",
    "        # Evaluate all possible moves and choose the best one\n",
    "        best_score = -float('inf')\n",
    "        best_action = None\n",
    "\n",
    "        for mi, mp in enumerate(my_positions):\n",
    "            if mp == yut.rule.FINISHED:\n",
    "                continue\n",
    "            for ys in available_yutscores:\n",
    "                shortcuts = [True, False] if self._is_shortcut_possible(mi) else [False]\n",
    "\n",
    "                for shortcut in shortcuts:\n",
    "                    legal_move, next_my_positions, next_enemy_positions, num_mals_caught = yut.rule.make_move(\n",
    "                        my_positions, enemy_positions, mi, ys, shortcut\n",
    "                    )\n",
    "                    if legal_move:\n",
    "                        # Calculate the score for this move\n",
    "                        throw_again = num_mals_caught > 0\n",
    "                        score = self.evaluate_score(next_my_positions, next_enemy_positions, throw_again)\n",
    "\n",
    "                        # Update best move\n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_action = (mi, ys, shortcut)\n",
    "\n",
    "        # Return the best action\n",
    "        if best_action is not None:\n",
    "            return best_action[0], best_action[1], best_action[2], \"\"\n",
    "\n",
    "        # Fallback (no legal moves)\n",
    "        return 0, available_yutscores[0], False, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Player 1 won!\n",
      "1: Player 1 won!\n",
      "2: Player 2 won!\n",
      "3: Player 2 won!\n",
      "4: Player 2 won!\n",
      "5: Player 1 won!\n",
      "6: Player 1 won!\n",
      "7: Player 2 won!\n",
      "8: Player 2 won!\n",
      "9: Player 2 won!\n",
      "10: Player 1 won!\n",
      "11: Player 1 won!\n",
      "12: Player 2 won!\n",
      "13: Player 1 won!\n",
      "14: Player 2 won!\n",
      "15: Player 2 won!\n",
      "16: Player 2 won!\n",
      "17: Player 2 won!\n",
      "18: Player 2 won!\n",
      "19: Player 1 won!\n",
      "20: Player 2 won!\n",
      "21: Player 2 won!\n",
      "22: Player 2 won!\n",
      "23: Player 1 won!\n",
      "24: Player 2 won!\n",
      "25: Player 1 won!\n",
      "26: Player 2 won!\n",
      "27: Player 2 won!\n",
      "28: Player 1 won!\n",
      "29: Player 1 won!\n",
      "30: Player 2 won!\n",
      "31: Player 2 won!\n",
      "32: Player 2 won!\n",
      "33: Player 2 won!\n",
      "34: Player 2 won!\n",
      "35: Player 1 won!\n",
      "36: Player 1 won!\n",
      "37: Player 2 won!\n",
      "38: Player 1 won!\n",
      "39: Player 1 won!\n",
      "40: Player 2 won!\n",
      "41: Player 1 won!\n",
      "42: Player 2 won!\n",
      "43: Player 1 won!\n",
      "44: Player 2 won!\n",
      "45: Player 1 won!\n",
      "46: Player 1 won!\n",
      "47: Player 2 won!\n",
      "48: Player 1 won!\n",
      "49: Player 2 won!\n",
      "50: Player 2 won!\n",
      "51: Player 2 won!\n",
      "52: Player 1 won!\n",
      "53: Player 2 won!\n",
      "54: Player 1 won!\n",
      "55: Player 2 won!\n",
      "56: Player 1 won!\n",
      "57: Player 1 won!\n",
      "58: Player 2 won!\n",
      "59: Player 2 won!\n",
      "60: Player 2 won!\n",
      "61: Player 1 won!\n",
      "62: Player 1 won!\n",
      "63: Player 1 won!\n",
      "64: Player 2 won!\n",
      "65: Player 2 won!\n",
      "66: Player 2 won!\n",
      "67: Player 2 won!\n",
      "68: Player 2 won!\n",
      "69: Player 2 won!\n",
      "70: Player 1 won!\n",
      "71: Player 1 won!\n",
      "72: Player 1 won!\n",
      "73: Player 2 won!\n",
      "74: Player 2 won!\n",
      "75: Player 1 won!\n",
      "76: Player 2 won!\n",
      "77: Player 1 won!\n",
      "78: Player 2 won!\n",
      "79: Player 2 won!\n",
      "80: Player 1 won!\n",
      "81: Player 2 won!\n",
      "82: Player 1 won!\n",
      "83: Player 1 won!\n",
      "84: Player 2 won!\n",
      "85: Player 1 won!\n",
      "86: Player 2 won!\n",
      "87: Player 2 won!\n",
      "88: Player 1 won!\n",
      "89: Player 1 won!\n",
      "90: Player 2 won!\n",
      "91: Player 1 won!\n",
      "92: Player 1 won!\n",
      "93: Player 2 won!\n",
      "94: Player 1 won!\n",
      "95: Player 1 won!\n",
      "96: Player 2 won!\n",
      "97: Player 1 won!\n",
      "98: Player 1 won!\n",
      "99: Player 2 won!\n",
      "Player 1 wins 45 times, with winrate of 0.45\n"
     ]
    }
   ],
   "source": [
    "# create a game engine\n",
    "engine = yut.engine.GameEngine()\n",
    "\n",
    "# create two game players\n",
    "player2 = MinimaxAkiraPlayer()\n",
    "player1 = MinimaxAkiraPlayer2()\n",
    "\n",
    "# simulate a game between two players with a given random seed\n",
    "num_trial = 100\n",
    "win_rate = 0\n",
    "# random_numbers = [random.randint(1, 10000) for _ in range(num_trial)]\n",
    "random_numbers = [x for x in range(num_trial)]\n",
    "for i, random_seed in enumerate(random_numbers):\n",
    "\twinner = engine.play( player1, player2, seed=random_seed )\n",
    "\tif winner == 0:\n",
    "\t\twin_rate += 1\n",
    "\t\tprint( str(i) + \": Player 1 won!\" )\n",
    "\telse:\n",
    "\t\tprint( str(i) + \": Player 2 won!\" )\n",
    "\n",
    "print(\"Player 1 wins \" + str(win_rate) + \" times, with winrate of \" + str(win_rate/num_trial) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
